{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21114689-a7a5-4af3-8c56-a989de93404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the autoreload extension\n",
    "%load_ext autoreload\n",
    "# Reload all modules (except those imported with %aimport) automatically\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../GP_Copilot_Webapp\")\n",
    "\n",
    "import concurrent.futures\n",
    "import time\n",
    "from requests.exceptions import Timeout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc3d90a-1acc-40dd-84e1-471222e42a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8a53f7-dde7-4ede-9d59-d13e64ec634c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d481efed-5aea-454a-a92c-68992e41844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get a list of modules that actually exist: \n",
    "modules_data = pd.read_csv('/Users/edwinhuang/Downloads/JobsOnCloud_2015-2025 - Sheet1-2.csv', header = 1)\n",
    "filtered = modules_data[modules_data['jobcount'] > 35]\n",
    "modules_that_exist = filtered.TASK_NAME.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "115804cb-4238-4d67-a968-da171fda8bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chroma path exists? True\n"
     ]
    }
   ],
   "source": [
    "## delete collections to restart \n",
    "## creating different vector stores: \n",
    "\n",
    "chroma_path = os.path.join('../GP_Copilot_Webapp', 'chroma')\n",
    "print(f'chroma path exists? {os.path.exists(chroma_path)}')\n",
    "client = chromadb.PersistentClient(path = chroma_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649c2a51-2455-4179-b0bb-9e3777e93108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1448750e-4b44-4c36-b6a0-24cf09ca9141",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections_to_create = ['genepattern_guide', 'genepattern_module_manifests','genepattern_module_readmes', 'genepattern_module_wrappers', 'genepattern_module_documentations', 'genepattern_threads']\n",
    "for col in collections_to_create:\n",
    "    client.get_or_create_collection(col)\n",
    "    # client.delete_collection(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b33c8335-7213-4aeb-82e7-6597bed5f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_text_to_file(text, filename):\n",
    "\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "\n",
    "def agent_summarization(agent, documents, document_type):\n",
    "    \"\"\"\n",
    "    Summarizes a documentation via agent\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    return result\n",
    "    for doc in tqdm(documents, desc=f\"Summarizing {document_type} with LLM\"):\n",
    "        output = agent(doc.page_content)\n",
    "        output_fp = f'{doc.metadata[\"module_name\"]}_{document_type}_LLM_summarized.txt'\n",
    "        doc.page_content = output\n",
    "        save_text_to_file(output, os.path.join('LLM generated docs', document_type, output_fp))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fa6be2b-25ba-4215-bead-6fb6ead5affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_text_to_file('test', os.path.join('LLM_generated_docs','manifests', 'manifest_test.txt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f030b035-3721-46ca-977f-c331fa2cb073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 155 manifests.\n",
      "There are a total of 78 read mes.\n",
      "There are a total of 902 threads. \n",
      "There are a total of 376 wrappers. \n",
      "MuPDF error: format error: No default Layer config\n",
      "\n",
      "MuPDF error: format error: No default Layer config\n",
      "\n",
      "MuPDF error: format error: No default Layer config\n",
      "\n",
      "MuPDF error: format error: No default Layer config\n",
      "\n",
      "MuPDF error: format error: No default Layer config\n",
      "\n",
      "MuPDF error: format error: No default Layer config\n",
      "\n",
      "MuPDF error: format error: No default Layer config\n",
      "\n",
      "MuPDF error: format error: No default Layer config\n",
      "\n",
      "There are a total of 257 documentation_files. \n",
      "There are a total of 280 genepattern guides. \n"
     ]
    }
   ],
   "source": [
    "## paths\n",
    "manifests = '/Users/edwinhuang/Documents/GitHub/llm-hackathon/scrapes/manifests'\n",
    "documentations = '/Users/edwinhuang/Documents/GitHub/llm-hackathon/scrapes/doc'\n",
    "wrappers = '/Users/edwinhuang/Documents/GitHub/llm-hackathon/scrapes/wrappers'\n",
    "threads = '/Users/edwinhuang/Documents/GitHub/llm-hackathon/scrapes/threads2'\n",
    "readmes = '/Users/edwinhuang/Desktop/documentations/readmes'\n",
    "\n",
    "manifest_docs, readme_docs, thread_docs, wrappers, documentation_files, guides = obtain_raw_documents(manifests, documentations, wrappers, threads, readmes, modules_that_exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15388156-6eda-44ab-b8b6-ba3aa9dd6493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(wrappers): 376\n",
      "len(thread_docs): 902\n",
      "len(original_questions): 596\n",
      "len(answers): 596\n",
      "len(manifest_docs): 155\n",
      "len(readme_docs): 78\n",
      "len(documentation_files): 257\n",
      "len(guides): 280\n"
     ]
    }
   ],
   "source": [
    "print(\"len(wrappers):\", len(wrappers))\n",
    "print(\"len(thread_docs):\", len(thread_docs))\n",
    "print(\"len(manifest_docs):\", len(manifest_docs))\n",
    "print(\"len(readme_docs):\", len(readme_docs))\n",
    "print(\"len(documentation_files):\", len(documentation_files))\n",
    "print(\"len(guides):\", len(guides))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21064ccf-cfbd-405f-a99e-2ba623fc78df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc in tqdm(wrappers, desc=\"Summarizing wrappers with LLM\"):\n",
    "#     output = code_agent(doc.page_content)\n",
    "#     output_fp = f'{doc.metadata[\"module_name\"]}_wrappers_LLM_summarized.txt'\n",
    "#     doc.page_content = output\n",
    "#     save_text_to_file(output, os.path.join('LLM generated docs', output_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3e6b976-0a3a-4d9e-94a0-148ed3a8d3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 78 read mes.\n"
     ]
    }
   ],
   "source": [
    "# for doc in tqdm(readme_docs, desc=\"Summarizing readmes with LLM\"):\n",
    "#     output = code_agent(doc.page_content)\n",
    "#     output_fp = f'{doc.metadata[\"module_name\"]}_readme_LLM_summarized.txt'\n",
    "#     doc.page_content = output\n",
    "#     save_text_to_file(output, os.path.join('LLM generated docs', output_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e07d2fd2-fd16-4acf-9474-7fd9d003c139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1768"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "for doc in wrappers+thread_docs + manifest_docs + readme_docs + documentation_files:\n",
    "    if 'source' in doc.metadata.keys():\n",
    "        i+=1\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e275a32-958d-4a23-b551-62409828dfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1768"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for doc in tqdm(documents, desc=f\"Summarizing {document_type} with LLM\"):\n",
    "    output = agent(doc.page_content)\n",
    "    output_fp = f'{doc.metadata[\"module_name\"]}_{document_type}_LLM_summarized.txt'\n",
    "    doc.page_content = output\n",
    "    save_text_to_file(output, os.path.join('LLM generated docs', document_type, output_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac0e6e36-727f-4593-a10c-26ece49b0cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = wrappers[:3]+thread_docs[:3] + manifest_docs[:3] + readme_docs[:3] + documentation_files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ee3a539f-9f33-42e1-bef0-aefb55fad838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle parallel execution\n",
    "def agent_run(agent, document):\n",
    "    \n",
    "    try:\n",
    "        result = agent(document)\n",
    "        document.page_content = result\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered: {e}\")\n",
    "        tqdm.write(\"Rate limit reached, sleeping for 61 seconds...\")\n",
    "        time.sleep(61)  # Sleep and retry\n",
    "        result = agent(document)\n",
    "        document.page_content = result\n",
    "\n",
    "    \n",
    "    return document\n",
    "        \n",
    "def run_parallel(documents, agent):\n",
    "    tasks = []\n",
    "    \n",
    "    # Calculate total iterations for progress bar\n",
    "    total_iterations = len(documents)\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor, tqdm(total=total_iterations, desc=\"Running summarization\") as pbar:\n",
    "        future_to_params = {}\n",
    "        # Submit tasks\n",
    "        for doc in documents:\n",
    "            future = executor.submit(agent_run, agent, doc)\n",
    "            future_to_params[future] = (agent, doc)\n",
    "        \n",
    "        # Collect results\n",
    "        results = []\n",
    "        for future in concurrent.futures.as_completed(future_to_params):\n",
    "            try:\n",
    "                results.append(future.result())  # Get the result\n",
    "            except Exception as e:\n",
    "                tqdm.write(f\"Unexpected error: {e}\")\n",
    "            pbar.update(1)  # Update progress bar\n",
    "\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7353d70e-6c28-43ff-b8f3-626a4ab77543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False, False]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['Seurat' in doc.page_content for doc in guides[0:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7e43a924-8244-49f9-8dbc-2bf831adf2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running summarization: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.53s/it]\n"
     ]
    }
   ],
   "source": [
    "from copilot.LLM_aided_rag import *\n",
    "results = run_parallel(guides[60:63], guides_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "063d2525-dd9c-48eb-acb0-5efae044f043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running summarization: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 376/376 [08:25<00:00,  1.35s/it]\n",
      "Running summarization: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 155/155 [03:32<00:00,  1.37s/it]\n",
      "Running summarization: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 78/78 [01:35<00:00,  1.23s/it]\n",
      "Running summarization: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 257/257 [05:28<00:00,  1.28s/it]\n",
      "Running summarization: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 280/280 [04:59<00:00,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(llm_wrappers): 376\n",
      "len(llm_manifests): 155\n",
      "len(llm_readmes): 78\n",
      "len(threads): 65\n",
      "len(llm_documentations): 257\n",
      "len(llm_guides): 280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from copilot.LLM_aided_rag import *\n",
    "llm_wrappers = run_parallel(wrappers, manifest_agent)\n",
    "llm_manifests = run_parallel(manifest_docs,manifest_agent)\n",
    "llm_readmes = run_parallel(readme_docs, documentation_agent)\n",
    "llm_documentations = run_parallel(documentation_files, documentation_agent)\n",
    "llm_guides = run_parallel(guides, guides_agent)\n",
    "print(\"len(llm_wrappers):\", len(llm_wrappers))\n",
    "print(\"len(llm_manifests):\", len(llm_manifests))\n",
    "print(\"len(llm_readmes):\", len(llm_readmes))\n",
    "print(\"len(threads):\", len(threads))\n",
    "print(\"len(llm_documentations):\", len(llm_documentations))\n",
    "print(\"len(llm_guides):\", len(llm_guides))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6cb7bc19-d278-42e1-967c-b218aa46e210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thread_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38c0d87-0eee-498f-9e04-666b68f307d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add metadata to page content:\n",
    "\n",
    "for sec in [wrappers, thread_docs, manifest_docs, readme_docs, documentation_files, guides]:\n",
    "    for doc in sec:\n",
    "        doc.page_content = metadata_formatter(doc.metadata) + doc.page_content\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bd43f1-b34f-43d3-b139-3fcc8ad0dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documentation_files[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7ee85ab7-73f3-41b5-b129-4c94bff6b54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520cd2fe67204f0795d119d498d41538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load into respective chroma dbs\n",
    "\n",
    "def load_files_into_vector_store(vector_store, documents):\n",
    "    \"\"\"\n",
    "    Loads files into the vector , returns retriever\n",
    "    \"\"\"\n",
    "    uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "    # Load the documents into the vector store\n",
    "    \n",
    "    # Assuming 'documents' is a list of texts and 'uuids' is a list of corresponding IDs\n",
    "    for doc, doc_id in tqdm(zip(documents, uuids), total=len(documents), desc=\"Adding Documents\"):\n",
    "        vector_store.add_documents([doc], ids=[doc_id])\n",
    "\n",
    "    print(f'Loaded {len(documents)} documents into the vector store')\n",
    "    return vector_store.as_retriever()\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = get_embeddings('fast')\n",
    "chroma_path = os.path.join('../GP_Copilot_Webapp', 'chroma')\n",
    "os.path.exists(chroma_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cc9987ec-222f-4067-b4fb-eaa5004cbec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['genepattern_guide',\n",
       " 'genepattern_module_manifests',\n",
       " 'genepattern_module_readmes',\n",
       " 'genepattern_module_wrappers',\n",
       " 'genepattern_module_documentations',\n",
       " 'genepattern_threads']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_assignments = dict(zip(collections_to_create, [llm_guides, llm_manifests, llm_readmes, llm_wrappers, llm_documentations, thread_docs]))\n",
    "collections_to_create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1fff0b69-9541-4c4f-b493-e7f5333355a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading documents for genepattern_guide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding Documents: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 280/280 [00:21<00:00, 12.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 280 documents into the vector store\n",
      "loading documents for genepattern_module_manifests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding Documents: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 155/155 [00:12<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 155 documents into the vector store\n",
      "loading documents for genepattern_module_readmes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding Documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 78/78 [00:06<00:00, 12.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 78 documents into the vector store\n",
      "loading documents for genepattern_module_wrappers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding Documents: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 376/376 [00:30<00:00, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 376 documents into the vector store\n",
      "loading documents for genepattern_module_documentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding Documents: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 257/257 [00:21<00:00, 12.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 257 documents into the vector store\n",
      "loading documents for genepattern_threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding Documents: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 902/902 [01:23<00:00, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 902 documents into the vector store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "doc_assignments = dict(zip(collections_to_create, [llm_guides, llm_manifests, llm_readmes, llm_wrappers, llm_documentations, thread_docs]))\n",
    "for col in collections_to_create:\n",
    "    print(f'loading documents for {col}')\n",
    "    client.get_or_create_collection(col)\n",
    "    vector_store = Chroma(client=client,\n",
    "                    embedding_function = embeddings,\n",
    "                    persist_directory = chroma_path,\n",
    "                    collection_name=col)\n",
    "    ret = load_files_into_vector_store(vector_store, doc_assignments[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e2998-00d3-472b-b3a0-0d4ca3ccab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## validate that docs are there:\n",
    "for col in collections_to_create:\n",
    "    get_vector_store(chroma_path, col)\n",
    "    # client.delete_collection(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cfea9a-6e22-4d3b-a1aa-ca28d46e2ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce0b271-d924-4592-bb3b-278661e88e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vector_store(\"GP_Copilot/chroma\", 'my_vector_store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1e334d-29da-4d86-9a98-165525e10ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections_to_create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bc67e248-9c7f-434e-abad-556ca02aa33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "page_content='### **Section 1: Summary**\n",
      "\n",
      "The document is about Seurat.Preprocessing, a GenePattern module that implements preprocessing steps for single-cell datasets using the Seurat package (version 4.0.3). Seurat.Preprocessing is part of the broader Seurat pipeline, which is a suite of tools for single-cell analysis. This module is designed to prepare datasets for downstream analyses and visualizations, such as clustering and dimensionality reduction. The intended use case is for researchers working with single-cell RNA sequencing data to preprocess their data for further analysis. The biological context is focused on single-cell datasets, potentially from various species, diseases, or tissues. Key tools and methods mentioned include Seurat, GenePattern, and R.\n",
      "\n",
      "### **Section 2: Structured Annotations**\n",
      "\n",
      "- `analysis_type`: Single-cell RNA sequencing data preprocessing\n",
      "- `use_case`: Preprocessing of single-cell datasets for downstream analyses and visualizations\n",
      "- `related_analyses`: Clustering, dimensionality reduction, differential gene expression analysis\n",
      "- `biological_context`: Single-cell datasets from various species, diseases, or tissues\n",
      "- `tools_or_modules`: Seurat, GenePattern, R\n",
      "- `file_formats`: RDS, PDF\n",
      "- `parameters`: \n",
      "  - `input_rds`: RDS file created by Seurat.QC\n",
      "  - `column_name`: Column name of percent mitochondrial genes\n",
      "  - `pattern`: Pattern to use to label mitochondrial genes\n",
      "  - `file_name`: Basename of the file to be saved\n",
      "  - `keep_scale_data`: Preserve the scale.data slot for the assays specified\n",
      "  - `first_feature`, `second_feature`, `third_feature`: Features to plot as violin plots for QC\n",
      "  - `min_n_features`, `max_n_features`, `max_percent_mitochondrial`: Filtering parameters\n",
      "  - `norm_method`: Method for normalization\n",
      "  - `scale_factor`: Scaling to be applied after normalization\n",
      "  - `feat_sel_method`: Method for feature selection\n",
      "  - `num_features`, `num_to_label`: Parameters for feature selection and labeling\n",
      "  - `numpcs`, `vdl_num_dims`, `vdhm_num_dims`, `cells`: Parameters for PCA and visualization\n",
      "\n",
      "### **Section 3: Potential Questions**\n",
      "\n",
      "1. How do I preprocess single-cell RNA sequencing data using Seurat?\n",
      "2. What is the purpose of the Seurat.Preprocessing module in GenePattern?\n",
      "3. How can I filter single-cell data based on the number of expressed genes and mitochondrial content?\n",
      "4. What are the typical downstream analyses after preprocessing single-cell data with Seurat.Preprocessing?\n",
      "5. How do I normalize and reduce the dimensionality of single-cell RNA sequencing data?\n",
      "6. What file formats are used as input and output for the Seurat.Preprocessing module?\n",
      "7. How can I customize the preprocessing steps in Seurat.Preprocessing, such as changing the normalization method or feature selection parameters?' metadata={'source': '/Users/edwinhuang/Documents/GitHub/llm-hackathon/scrapes/doc/Seurat.Preprocessing.html', 'file_name': 'Seurat.Preprocessing.html', 'module_name': 'doc', 'document_type': 'documentation'}\n",
      "-----------------------------------------\n",
      "page_content='### Section 1: Summary\n",
      "The document describes the Seurat.BatchCorrection module, which is part of the Seurat pipeline. This module implements a batch correction algorithm for integrating multiple single-cell datasets and identifying shared cell states across different datasets. The intended use case is to correct for batch effects in single-cell RNA-seq data, allowing for downstream analyses and visualizations. The biological context is single-cell gene expression data, and the module is designed to work with various input file formats, including .txt, .rds, and .tsv. The module produces output files, including a batch-corrected expression matrix, a UMAP plot, and a violin plot. The Seurat.BatchCorrection module is part of the GenePattern suite and is distributed under a modified BSD license.\n",
      "\n",
      "### Section 2: Structured Annotations\n",
      "- `analysis_type`: Batch correction for single-cell RNA-seq data\n",
      "- `use_case`: Correcting for batch effects in single-cell gene expression data\n",
      "- `related_analyses`: Downstream analyses, such as clustering, differential gene expression, and visualization\n",
      "- `biological_context`: Single-cell gene expression data, potentially from various species, diseases, or tissues\n",
      "- `tools_or_modules`: Seurat, GenePattern, Seurat.QC, Seurat.Clustering\n",
      "- `file_formats`: Input: .txt, .rds, .tsv; Output: .rds, .pdf, .txt\n",
      "- `parameters`: \n",
      "  - `input_files`: Gene expression matrices\n",
      "  - `use_batch_names`: Map input files to batch numbers (default: TRUE)\n",
      "  - `ncomps`: Number of principal components for PCA (default: 50)\n",
      "  - `nCount_RNA`: Produce violin plot of molecules detected (default: TRUE)\n",
      "  - `nFeature_RNA`: Produce violin plot of genes detected (default: TRUE)\n",
      "  - `output_file_name`: Base name for output files (default: 'batch_correction_results')\n",
      "\n",
      "### Section 3: Potential questions\n",
      "- How do I correct for batch effects in my single-cell RNA-seq data?\n",
      "- What is the Seurat.BatchCorrection module, and how does it work?\n",
      "- How can I integrate multiple single-cell datasets using Seurat?\n",
      "- What are the input and output file formats for the Seurat.BatchCorrection module?\n",
      "- What are the parameters that need to be set for the Seurat.BatchCorrection module?\n",
      "- How can I visualize the results of batch correction using Seurat?\n",
      "- What are the downstream analyses that can be performed after batch correction using Seurat?' metadata={'source': '/Users/edwinhuang/Documents/GitHub/llm-hackathon/scrapes/doc/Seurat.IntegrateData.html', 'file_name': 'Seurat.IntegrateData.html', 'module_name': 'doc', 'document_type': 'documentation'}\n",
      "-----------------------------------------\n",
      "page_content='### **Section 1: Summary**\n",
      "The Seurat.QC module is part of the Seurat pipeline, specifically designed for quality control steps. It is typically the first step in the Seurat Suite modules, unless batch correction is being performed, in which case Seurat.BatchCorrection should be run first. This module aims to provide a quick overview of basic single-cell datasets, with the resultant preprocessed dataset usable for downstream analyses and visualizations, such as those provided by Seurat.Preprocessing. The analysis methodology involves single-cell RNA sequencing, and the intended use case is for biological research, particularly in the context of genomics and transcriptomics. The biological context includes species, disease, tissue, and cell lines, with a focus on single-cell data. Tools and methods mentioned include Seurat, GenePattern, and R, with file formats including .tar.gz, .zip, .loom, .rds, .pdf, and .txt.\n",
      "\n",
      "### **Section 2: Structured Annotations**\n",
      "- `analysis_type`: Single-cell RNA sequencing quality control\n",
      "- `use_case`: Quality control and preprocessing of single-cell RNA sequencing data for downstream analyses\n",
      "- `related_analyses`: Downstream analyses such as differential gene expression, clustering, and visualization using tools like Seurat.Preprocessing, Seurat.BatchCorrection, and Conos\n",
      "- `biological_context`: Single-cell data from various species, diseases, tissues, and cell lines\n",
      "- `tools_or_modules`: Seurat, GenePattern, R\n",
      "- `file_formats`: .tar.gz, .zip, .loom, .rds, .pdf, .txt\n",
      "- `parameters`: \n",
      "  - `input_file`: Path to the input file containing raw single-cell data\n",
      "  - `column_name`: Column name of percent mitochondrial genes\n",
      "  - `pattern`: Pattern to label mitochondrial genes\n",
      "  - `first_feature`, `second_feature`, `third_feature`: Features to plot as violin plots\n",
      "  - `file_name`: Basename of the file to be saved\n",
      "  - `export_txt`: Whether to create a TXT file compatible with other modules\n",
      "\n",
      "### **Section 3: Potential questions**\n",
      "1. How do I perform quality control on single-cell RNA sequencing data using Seurat?\n",
      "2. What are the input and output file formats supported by the Seurat.QC module?\n",
      "3. Can I use Seurat.QC for batch correction, or do I need to run Seurat.BatchCorrection separately?\n",
      "4. How do I visualize the results of the quality control step in Seurat.QC?\n",
      "5. What are the typical downstream analyses that can be performed using the output of Seurat.QC?\n",
      "6. Is Seurat.QC compatible with .loom files from the Human Cell Atlas (HCA)?\n",
      "7. How do I troubleshoot errors caused by large datasets when creating a TXT file with Seurat.QC?' metadata={'source': '/Users/edwinhuang/Documents/GitHub/llm-hackathon/scrapes/doc/Seurat.QC.html', 'file_name': 'Seurat.QC.html', 'module_name': 'doc', 'document_type': 'documentation'}\n"
     ]
    }
   ],
   "source": [
    "for doc in llm_documentations:\n",
    "    if 'Seurat.QC' in doc.page_content:\n",
    "        print('-----------------------------------------')\n",
    "        print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e47a9cfb-76f4-40ff-a7b5-de59c574d545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab3923c45d64547b7aee56c6a8ac2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store: genepattern_module_documentations found. Number of documents in collection: 257\n",
      "Using llama-mini\n"
     ]
    }
   ],
   "source": [
    "vector_db_query = f\"\"\"\n",
    "        \"Seurat\": [\"Seurat.Preprocessing\", \"Seurat.Clustering\", \"Seurat.VisualizeMarkerExpression\", \"Seurat.IntegrateData\", \"Seurat.QC\"]\n",
    "        \"\"\"\n",
    "retrieved_docs = retrieve_documents(chroma_path, vector_db_query, ['genepattern_module_documentations'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "82a3b961-b7b7-42ee-ad65-b55a6cd2aba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "page_content='### **Section 1: Summary**\n",
      "\n",
      "The document is about Seurat.Preprocessing, a GenePattern module that implements preprocessing steps for single-cell datasets using the Seurat package (version 4.0.3). Seurat.Preprocessing is part of the broader Seurat pipeline, which is a suite of tools for single-cell analysis. This module is designed to prepare datasets for downstream analyses and visualizations, such as clustering and dimensionality reduction. The intended use case is for researchers working with single-cell RNA sequencing data to preprocess their data for further analysis. The biological context is focused on single-cell datasets, potentially from various species, diseases, or tissues. Key tools and methods mentioned include Seurat, GenePattern, and R.\n",
      "\n",
      "### **Section 2: Structured Annotations**\n",
      "\n",
      "- `analysis_type`: Single-cell RNA sequencing data preprocessing\n",
      "- `use_case`: Preprocessing of single-cell datasets for downstream analyses and visualizations\n",
      "- `related_analyses`: Clustering, dimensionality reduction, differential gene expression analysis\n",
      "- `biological_context`: Single-cell datasets from various species, diseases, or tissues\n",
      "- `tools_or_modules`: Seurat, GenePattern, R\n",
      "- `file_formats`: RDS, PDF\n",
      "- `parameters`: \n",
      "  - `input_rds`: RDS file created by Seurat.QC\n",
      "  - `column_name`: Column name of percent mitochondrial genes\n",
      "  - `pattern`: Pattern to use to label mitochondrial genes\n",
      "  - `file_name`: Basename of the file to be saved\n",
      "  - `keep_scale_data`: Preserve the scale.data slot for the assays specified\n",
      "  - `first_feature`, `second_feature`, `third_feature`: Features to plot as violin plots for QC\n",
      "  - `min_n_features`, `max_n_features`, `max_percent_mitochondrial`: Filtering parameters\n",
      "  - `norm_method`: Method for normalization\n",
      "  - `scale_factor`: Scaling to be applied after normalization\n",
      "  - `feat_sel_method`: Method for feature selection\n",
      "  - `num_features`, `num_to_label`: Parameters for feature selection and labeling\n",
      "  - `numpcs`, `vdl_num_dims`, `vdhm_num_dims`, `cells`: Parameters for PCA and visualization\n",
      "\n",
      "### **Section 3: Potential Questions**\n",
      "\n",
      "1. How do I preprocess single-cell RNA sequencing data using Seurat?\n",
      "2. What is the purpose of the Seurat.Preprocessing module in GenePattern?\n",
      "3. How can I filter single-cell data based on the number of expressed genes and mitochondrial content?\n",
      "4. What are the typical downstream analyses after preprocessing single-cell data with Seurat.Preprocessing?\n",
      "5. How do I normalize and reduce the dimensionality of single-cell RNA sequencing data?\n",
      "6. What file formats are used as input and output for the Seurat.Preprocessing module?\n",
      "7. How can I customize the preprocessing steps in Seurat.Preprocessing, such as changing the normalization method or feature selection parameters?' metadata={'document_type': 'documentation', 'file_name': 'Seurat.Preprocessing.html', 'module_name': 'doc', 'source': '/Users/edwinhuang/Documents/GitHub/llm-hackathon/scrapes/doc/Seurat.Preprocessing.html'}\n",
      "----------------------------------------------------\n",
      "page_content='### **Section 1: Summary**\n",
      "The Seurat.QC module is part of the Seurat pipeline, specifically designed for quality control steps. It is typically the first step in the Seurat Suite modules, unless batch correction is being performed, in which case Seurat.BatchCorrection should be run first. This module aims to provide a quick overview of basic single-cell datasets, with the resultant preprocessed dataset usable for downstream analyses and visualizations, such as those provided by Seurat.Preprocessing. The analysis methodology involves single-cell RNA sequencing, and the intended use case is for biological research, particularly in the context of genomics and transcriptomics. The biological context includes species, disease, tissue, and cell lines, with a focus on single-cell data. Tools and methods mentioned include Seurat, GenePattern, and R, with file formats including .tar.gz, .zip, .loom, .rds, .pdf, and .txt.\n",
      "\n",
      "### **Section 2: Structured Annotations**\n",
      "- `analysis_type`: Single-cell RNA sequencing quality control\n",
      "- `use_case`: Quality control and preprocessing of single-cell RNA sequencing data for downstream analyses\n",
      "- `related_analyses`: Downstream analyses such as differential gene expression, clustering, and visualization using tools like Seurat.Preprocessing, Seurat.BatchCorrection, and Conos\n",
      "- `biological_context`: Single-cell data from various species, diseases, tissues, and cell lines\n",
      "- `tools_or_modules`: Seurat, GenePattern, R\n",
      "- `file_formats`: .tar.gz, .zip, .loom, .rds, .pdf, .txt\n",
      "- `parameters`: \n",
      "  - `input_file`: Path to the input file containing raw single-cell data\n",
      "  - `column_name`: Column name of percent mitochondrial genes\n",
      "  - `pattern`: Pattern to label mitochondrial genes\n",
      "  - `first_feature`, `second_feature`, `third_feature`: Features to plot as violin plots\n",
      "  - `file_name`: Basename of the file to be saved\n",
      "  - `export_txt`: Whether to create a TXT file compatible with other modules\n",
      "\n",
      "### **Section 3: Potential questions**\n",
      "1. How do I perform quality control on single-cell RNA sequencing data using Seurat?\n",
      "2. What are the input and output file formats supported by the Seurat.QC module?\n",
      "3. Can I use Seurat.QC for batch correction, or do I need to run Seurat.BatchCorrection separately?\n",
      "4. How do I visualize the results of the quality control step in Seurat.QC?\n",
      "5. What are the typical downstream analyses that can be performed using the output of Seurat.QC?\n",
      "6. Is Seurat.QC compatible with .loom files from the Human Cell Atlas (HCA)?\n",
      "7. How do I troubleshoot errors caused by large datasets when creating a TXT file with Seurat.QC?' metadata={'document_type': 'documentation', 'file_name': 'Seurat.QC.html', 'module_name': 'doc', 'source': '/Users/edwinhuang/Documents/GitHub/llm-hackathon/scrapes/doc/Seurat.QC.html'}\n",
      "----------------------------------------------------\n",
      "page_content='### **Section 1: Summary**\n",
      "The Seurat.Clustering module is part of the larger Seurat pipeline, which is an R package designed for quality control, analysis, and exploration of single-cell RNA-seq data. The Seurat.Clustering module specifically performs UMAP clustering and marker identification on single-cell RNA-Seq data. The module uses Seurat version 3.0.2 and performs the following steps: FindNeighbors, FindClusters, RunUMAP, and DimPlot. The intended use case is to identify and interpret sources of heterogeneity from single-cell transcriptomic measurements and to integrate diverse types of single-cell data. Typical downstream or companion analyses may include differential gene expression analysis, pathway analysis, or further clustering analysis. The biological context is single-cell RNA-seq data, and the tools, methods, datasets, or file formats mentioned include Seurat, UMAP, RDS files, and CSV files.\n",
      "\n",
      "### **Section 2: Structured Annotations**\n",
      "- `analysis_type`: UMAP clustering and marker identification for single-cell RNA-seq data\n",
      "- `use_case`: Identify and interpret sources of heterogeneity from single-cell transcriptomic measurements\n",
      "- `related_analyses`: Differential gene expression analysis, pathway analysis, further clustering analysis\n",
      "- `biological_context`: Single-cell RNA-seq data\n",
      "- `tools_or_modules`: Seurat, UMAP, GenePattern\n",
      "- `file_formats`: RDS, CSV, PDF\n",
      "- `parameters`: \n",
      "  - `input seurat rds file`: A RDS file containing a Seurat object\n",
      "  - `output filename`: The output filename prefix used for all output files\n",
      "  - `maximum dimension`: The maximum number of clusters to attempt to find\n",
      "  - `resolution`: The resolution to use to find clusters\n",
      "  - `reduction`: The reduction to use (UMAP)\n",
      "  - `seed`: The random number seed to use\n",
      "\n",
      "### **Section 3: Potential Questions**\n",
      "- What is the purpose of the Seurat.Clustering module?\n",
      "- How does the Seurat.Clustering module perform UMAP clustering and marker identification?\n",
      "- What are the input and output files for the Seurat.Clustering module?\n",
      "- What are the parameters that can be adjusted in the Seurat.Clustering module?\n",
      "- What is the biological context of the Seurat.Clustering module?\n",
      "- What are some potential downstream or companion analyses for the Seurat.Clustering module?\n",
      "- How does the Seurat.Clustering module integrate with other tools and workflows in GenePattern?' metadata={'document_type': 'documentation', 'file_name': 'Seurat.Clustering.html', 'module_name': 'doc', 'source': '/Users/edwinhuang/Documents/GitHub/llm-hackathon/scrapes/doc/Seurat.Clustering.html'}\n",
      "----------------------------------------------------\n",
      "page_content='### Section 1: Summary\n",
      "The document describes the Seurat.BatchCorrection module, which is part of the Seurat pipeline. This module implements a batch correction algorithm for integrating multiple single-cell datasets and identifying shared cell states across different datasets. The intended use case is to correct for batch effects in single-cell RNA-seq data, allowing for downstream analyses and visualizations. The biological context is single-cell gene expression data, and the module is designed to work with various input file formats, including .txt, .rds, and .tsv. The module produces output files, including a batch-corrected expression matrix, a UMAP plot, and a violin plot. The Seurat.BatchCorrection module is part of the GenePattern suite and is distributed under a modified BSD license.\n",
      "\n",
      "### Section 2: Structured Annotations\n",
      "- `analysis_type`: Batch correction for single-cell RNA-seq data\n",
      "- `use_case`: Correcting for batch effects in single-cell gene expression data\n",
      "- `related_analyses`: Downstream analyses, such as clustering, differential gene expression, and visualization\n",
      "- `biological_context`: Single-cell gene expression data, potentially from various species, diseases, or tissues\n",
      "- `tools_or_modules`: Seurat, GenePattern, Seurat.QC, Seurat.Clustering\n",
      "- `file_formats`: Input: .txt, .rds, .tsv; Output: .rds, .pdf, .txt\n",
      "- `parameters`: \n",
      "  - `input_files`: Gene expression matrices\n",
      "  - `use_batch_names`: Map input files to batch numbers (default: TRUE)\n",
      "  - `ncomps`: Number of principal components for PCA (default: 50)\n",
      "  - `nCount_RNA`: Produce violin plot of molecules detected (default: TRUE)\n",
      "  - `nFeature_RNA`: Produce violin plot of genes detected (default: TRUE)\n",
      "  - `output_file_name`: Base name for output files (default: 'batch_correction_results')\n",
      "\n",
      "### Section 3: Potential questions\n",
      "- How do I correct for batch effects in my single-cell RNA-seq data?\n",
      "- What is the Seurat.BatchCorrection module, and how does it work?\n",
      "- How can I integrate multiple single-cell datasets using Seurat?\n",
      "- What are the input and output file formats for the Seurat.BatchCorrection module?\n",
      "- What are the parameters that need to be set for the Seurat.BatchCorrection module?\n",
      "- How can I visualize the results of batch correction using Seurat?\n",
      "- What are the downstream analyses that can be performed after batch correction using Seurat?' metadata={'document_type': 'documentation', 'file_name': 'Seurat.IntegrateData.html', 'module_name': 'doc', 'source': '/Users/edwinhuang/Documents/GitHub/llm-hackathon/scrapes/doc/Seurat.IntegrateData.html'}\n",
      "----------------------------------------------------\n",
      "page_content='### Section 1: Summary\n",
      "The module name is Seurat.VisualizeMarkerExpression, which is part of the bigger Seurat pipeline. This module is designed to visualize marker expression as violin plots and on a UMap, specifically after using Seurat.Clustering. The analysis methodology involves visualizing the expression of provided markers, which falls under the category of single-cell analysis, often used in RNA-seq studies. The intended use case is for researchers to visually understand how specific genes are expressed across different cell types or conditions within their single-cell dataset. Typical downstream analyses might include differential gene expression analysis or further clustering based on the visualized markers. The biological context is not strictly defined but is applicable to any species or disease model where single-cell RNA sequencing is used. Key tools and methods mentioned include Seurat, a popular R package for single-cell genomics, and UMap for dimensionality reduction. The module can handle RDS files as input and produces PDF files as output.\n",
      "\n",
      "### Section 2: Structured Annotations\n",
      "- `analysis_type`: Visualization of Marker Expression - Single-Cell RNA-seq\n",
      "- `use_case`: Visualizing gene expression across cell types or conditions in single-cell datasets\n",
      "- `related_analyses`: Differential Gene Expression, Clustering, Cell Fate Analysis\n",
      "- `biological_context`: Single-cell RNA sequencing; applicable to various organisms, diseases, and cell types\n",
      "- `tools_or_modules`: Seurat, UMap\n",
      "- `file_formats`: RDS (input), PDF (output)\n",
      "- `parameters`: \n",
      "  - `input_file`: RDS file to load\n",
      "  - `genes`: List of genes to visualize\n",
      "  - `group_plots`: How to group plots (Default='Horizontally')\n",
      "  - `output_file_name`: Basename of the file to be saved (default='SeuratMarkers')\n",
      "\n",
      "### Section 3: Potential Questions\n",
      "1. How can I visualize marker gene expression in my single-cell RNA-seq data?\n",
      "2. What module in Seurat is used for creating violin plots of marker genes?\n",
      "3. How do I visualize the expression of specific genes across different cell types in a UMap?\n",
      "4. What are the parameters required for running Seurat.VisualizeMarkerExpression?\n",
      "5. Can Seurat.VisualizeMarkerExpression handle datasets from any organism or is it limited to specific species?\n",
      "6. What kind of file formats does Seurat.VisualizeMarkerExpression support as input and output?\n",
      "7. How does Seurat.VisualizeMarkerExpression differ from other visualization tools in single-cell analysis pipelines?\n",
      "8. What version of R is compatible with Seurat.VisualizeMarkerExpression?\n",
      "9. Where can I find more information or support for using Seurat.VisualizeMarkerExpression?\n",
      "10. How can I customize the output of Seurat.VisualizeMarkerExpression, such as changing the plot layout or colors?' metadata={'document_type': 'documentation', 'file_name': 'Seurat.VisualizeMarkerExpression.html', 'module_name': 'doc', 'source': '/Users/edwinhuang/Documents/GitHub/llm-hackathon/scrapes/doc/Seurat.VisualizeMarkerExpression.html'}\n"
     ]
    }
   ],
   "source": [
    "for doc in retrieved_docs:\n",
    "    if 'Seurat' in doc.page_content:\n",
    "        print('----------------------------------------------------')\n",
    "        print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30214a99-12ff-46b1-ac79-c94915c3b47d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
